{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# home\n",
    "[show](#show)\n",
    "\n",
    "[show all](#show-all)\n",
    "\n",
    "[barbosa method](#Barbosa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create workflows\n",
    "\n",
    "* `row = test_name, workload_len, resources, budget_ratio, small, medium, large, bandwidth`\n",
    "* each resource: `[1, 1, 3]` == `[power is 1, price is 1, count is 3]`\n",
    "* `t` is the timeslot, and it is multiplied by 60, so 0.0833333 means 5 minutes and 1 means 60 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run all\n",
    "runs the workflow with new workflow structures (based on the test), and different deadline and bufdgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "successful, resources = run_all(verbose=True, return_resources=True)\n",
    "successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test for changing the tasks' execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_task_info(cloud_resources):\n",
    "    for r in range(cloud_resources.len):\n",
    "        for i, t in enumerate(cloud_resources.tasksOfResource[r]):\n",
    "            t.task.schedule = i\n",
    "            t.task.resource = r\n",
    "\n",
    "def deviate_task_runtimes(cloud_resources, deviation=0.3):\n",
    "    for r in range(cloud_resources.len):\n",
    "        for i, t in enumerate(cloud_resources.tasksOfResource[r]):\n",
    "            pred = t.task.predecessor\n",
    "            coef = max(0, np.random.normal(0, deviation))\n",
    "            t.EFT += (t.EFT - t.EST) * coef\n",
    "\n",
    "def correct_in_resource(cloud_resources):\n",
    "    changed = False\n",
    "    for r in range(cloud_resources.len):\n",
    "        for i, t in enumerate(cloud_resources.tasksOfResource[r]):\n",
    "            pred = t.task.predecessor\n",
    "            if i + 1 < len(cloud_resources.tasksOfResource[r]):\n",
    "                u = cloud_resources.tasksOfResource[r][i + 1]\n",
    "                if u.EST < t.EFT:\n",
    "                    changed = True\n",
    "                    delta = t.EFT - u.EST\n",
    "#                     print(f'r: {r}, i: {i}, t: ({t.EST},{t.EFT}), u: ({u.EST},{u.EFT}), new u: ({t.EFT},{u.EFT+delta}), delta: {delta}')\n",
    "                    u.EST = t.EFT\n",
    "                    u.EFT = u.EFT + delta\n",
    "    return changed\n",
    "\n",
    "def correct_successors(cloud_resources):\n",
    "    changed = False\n",
    "    for tos in cloud_resources.tasksOfResource:\n",
    "        for t in tos:\n",
    "            for s in t.task.successor:\n",
    "                delay = t.task.successor[s]/cloud_resources.bandwidth\n",
    "                if t.task.resource == t.task.graph.tasks[s].resource:\n",
    "                    delay = 0\n",
    "                r = t.task.graph.tasks[s].resource\n",
    "                if t.EFT + delay > cloud_resources.tasksOfResource[r][t.task.graph.tasks[s].schedule].EST:\n",
    "                    changed = True\n",
    "#                     print(f'successor: {s}')\n",
    "#                     print(f'   resources for t and s: {t.task.resource}, {t.task.graph.tasks[s].resource}')\n",
    "#                     print(f'   {t.EFT} --> ({delay}) --> {cloud_resources.tasksOfResource[r][t.task.graph.tasks[s].schedule].EST}')\n",
    "                    delta = t.EFT + delay - cloud_resources.tasksOfResource[r][t.task.graph.tasks[s].schedule].EST\n",
    "                    cloud_resources.tasksOfResource[r][t.task.graph.tasks[s].schedule].EST += delta\n",
    "                    cloud_resources.tasksOfResource[r][t.task.graph.tasks[s].schedule].EFT += delta\n",
    "    return changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_deviation_success(resources, deviation, verbose=False):\n",
    "    (cloud_resources, cost_list, makespan_list, constraint,\n",
    "     constraint_values, jobs, graph_set, names, workload_len, resources_set) = resources\n",
    "    store_task_info(cloud_resources)\n",
    "\n",
    "    deviate_task_runtimes(cloud_resources, deviation)\n",
    "\n",
    "    while True:\n",
    "        if not correct_in_resource(cloud_resources):\n",
    "            break\n",
    "        while correct_successors(cloud_resources):\n",
    "            pass\n",
    "\n",
    "    if verbose:\n",
    "        show_results(cloud_resources, cost_list, makespan_list, constraint,\n",
    "                     constraint_values, jobs, graph_set, names, workload_len, resources_set)\n",
    "        show_schedule(cloud_resources)\n",
    "    success = is_successful(cloud_resources, cost_list, makespan_list, constraint,\n",
    "                  constraint_values, jobs, graph_set, names, workload_len)\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def deviation_success_report(deviation):\n",
    "    successful, resources = run_all(verbose=False, return_resources=True)\n",
    "    after = check_deviation_success(resources, deviation)\n",
    "    return successful, after\n",
    "\n",
    "results = dict()\n",
    "for deviation in [0.0, 0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064]:\n",
    "    result = list(map(lambda x: [print(x, deviation), deviation_success_report(deviation), clear_output(wait=True)], range(5)))\n",
    "    results[deviation] = np.mean([1.0 if r[1][0] else 0.0 for r in result]), np.mean([1.0 if r[1][1] else 0.0 for r in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = list(map(lambda x: [run_all(), clear_output(wait=True)], range(20)))\n",
    "np.mean([1.0 if r[0] else 0.0 for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduling Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Definitions.MultiWorkflow.JobList import Constraint, JobItem\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import Scheduler.ICPCP\n",
    "import Scheduler.HEFT\n",
    "import Scheduler.BHEFT\n",
    "import Definitions.Resources\n",
    "import Scheduler.BudgetPessimistic\n",
    "import Scheduler.DeadlineOptimisticAlpha\n",
    "import copy\n",
    "import Scheduler.Multi_Workflow\n",
    "\n",
    "from db.definitions import Test\n",
    "import pickle\n",
    "import Definitions\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def run_all(verbose=False, return_resources=False):\n",
    "    create_pickle()\n",
    "\n",
    "    row, test, job, constraint, names, sizes = read_jobs()\n",
    "    test.time_slot = 1\n",
    "    for r in test.resource_array:\n",
    "        r[1] *= 12\n",
    "    bandwidth, workload_len, timeslot_list, powers, prices, numbers, power_list, price_list, timeslot_list, resource_spec, main_resources = create_resources(test)\n",
    "    makespan_list, cost_list, resources_set, graph_set, constraint_values = calculate_reference_plans(workload_len, main_resources, job, constraint, verbose=verbose)\n",
    "\n",
    "    to_write = (bandwidth, workload_len, timeslot_list, powers, prices, numbers, power_list, \n",
    "                price_list, timeslot_list, resource_spec, main_resources,\n",
    "                makespan_list, cost_list, resources_set, graph_set, constraint_values)\n",
    "\n",
    "    pickle.dump(to_write, open('refrence_plan2.pickle', 'wb'))\n",
    "\n",
    "    read_object = pickle.load(open('refrence_plan2.pickle', 'rb'))\n",
    "\n",
    "    bandwidth, workload_len, timeslot_list, powers, prices, numbers, power_list, price_list, timeslot_list, resource_spec, main_resources, makespan_list, cost_list, resources_set, graph_set, constraint_values = read_object\n",
    "\n",
    "    jobs, cloud_resources = create_multi_workflow_resouces(test, resources_set, constraint, cost_list, \n",
    "                                                           makespan_list, job, graph_set, constraint_values)\n",
    "    fair_policy(workload_len, jobs, cloud_resources)\n",
    "    successful_sched = is_successful(cloud_resources, cost_list, makespan_list, constraint,\n",
    "                                     constraint_values, jobs, graph_set, names, workload_len)\n",
    "    if verbose:\n",
    "        show_results(cloud_resources, cost_list, makespan_list, constraint,\n",
    "                     constraint_values, jobs, graph_set, names, workload_len, resources_set)\n",
    "        show_schedule(cloud_resources)\n",
    "        if successful_sched:\n",
    "            print('successful scheduling')\n",
    "        else:\n",
    "            print('not successful')\n",
    "    if return_resources:\n",
    "        return successful_sched, (cloud_resources, cost_list, makespan_list, constraint,\n",
    "                                  constraint_values, jobs, graph_set, names, workload_len, resources_set)\n",
    "    return successful_sched\n",
    "\n",
    "\n",
    "def create_pickle():\n",
    "    row = 'test1', 10, '{\"t\": 1, \"r\": [[1, 1, 6], [2, 3, 3]]}', 0.5, 1, 0, 0, 1e50\n",
    "\n",
    "    test = Test(row)\n",
    "    test.c_resource = 0.8\n",
    "    job, constraint, names, sizes = Scheduler.Multi_Workflow.make_workload(test)\n",
    "\n",
    "    names = []\n",
    "    for j in job:\n",
    "        i = 1\n",
    "        while f'{j.type[:-1]}:{i}' in names:\n",
    "            i += 1\n",
    "        j.name = f'{j.type[:-1]}:{i}'\n",
    "        names.append(f'{j.type[:-1]}:{i}')\n",
    "\n",
    "    [j.name for j in job]\n",
    "    cnstr = [c is Constraint.budget for c in constraint]\n",
    "    variable = (row, test, job, cnstr, names, sizes)\n",
    "    pickle.dump(variable, open('dump.pickle', 'wb'))\n",
    "\n",
    "\n",
    "def read_jobs():\n",
    "    row, test, job, cnstr, names, sizes = pickle.load(open('dump.pickle', 'rb'))\n",
    "    constraint = [Constraint.budget if b else Constraint.deadline for b in cnstr]\n",
    "    return row, test, job, constraint, names, sizes\n",
    "\n",
    "\n",
    "def create_resources(test):\n",
    "    bandwidth = test.bandwidth\n",
    "    workload_len = test.workload_len\n",
    "    timeslot_list = []\n",
    "    powers = []\n",
    "    prices = []\n",
    "    numbers = []\n",
    "    for r in test.resource_array:\n",
    "        powers.append(r[0])\n",
    "        prices.append(r[1])\n",
    "        numbers.append(r[2])\n",
    "\n",
    "    power_list, price_list, timeslot_list = [], [], []\n",
    "    for i in range(len(test.resource_array)):\n",
    "        power_list += [powers[i]] * numbers[i]\n",
    "        price_list += [prices[i]] * numbers[i]\n",
    "        timeslot_list += [60 * test.time_slot] * numbers[i]\n",
    "\n",
    "    resource_spec = (power_list, price_list, timeslot_list)\n",
    "\n",
    "    main_resources = Definitions.Resources.CostAwareResources(resource_spec[0], resource_spec[1], resource_spec[2],bandwidth)\n",
    "    \n",
    "    return bandwidth, workload_len, timeslot_list, powers, prices, numbers, power_list, price_list, timeslot_list, resource_spec, main_resources\n",
    "\n",
    "\n",
    "def calculate_reference_plans(workload_len, main_resources, job, constraint, verbose=True):\n",
    "    makespan_list = []\n",
    "    cost_list = []\n",
    "    resources_set = []\n",
    "    graph_set = []\n",
    "    constraint_values = []\n",
    "\n",
    "    for i in range(workload_len):\n",
    "        resources = copy.deepcopy(main_resources)\n",
    "        g = copy.deepcopy(job[i])\n",
    "        Scheduler.HEFT.schedule(g, resources)\n",
    "        g_heft = g\n",
    "        cost = resources.plan_cost\n",
    "        makespan = resources.makespan\n",
    "\n",
    "        heft_resources = resources\n",
    "\n",
    "        if constraint[i] is Constraint.budget:\n",
    "            c = 'Budget'\n",
    "            budget_factor = np.random.normal(8, 3) if random.random() >= 0.2 else np.random.normal(2, 1.4)\n",
    "            attempts = 3\n",
    "            while attempts > 0:\n",
    "                attempts -= 1\n",
    "                resources = copy.deepcopy(main_resources)\n",
    "                g = copy.deepcopy(job[i])\n",
    "                Scheduler.BHEFT.schedule(g, resources, cost * budget_factor)\n",
    "                if cost * budget_factor >= resources.plan_cost:\n",
    "                    break\n",
    "                budget_factor = np.random.normal(8, 3) if random.random() >= 0.2 else np.random.normal(2, 1.4)\n",
    "\n",
    "            constraint_factor = budget_factor\n",
    "            constraint_value = cost * budget_factor\n",
    "        else:\n",
    "            c = 'Deadline'\n",
    "            deadline_factor = np.random.normal(8, 1.4) if random.random() >= 0.2 else np.random.normal(2, 1.4)\n",
    "\n",
    "            resources = heft_resources\n",
    "            attempts = 3\n",
    "            while attempts > 0:\n",
    "                attempts -= 1\n",
    "                resources = copy.deepcopy(main_resources)\n",
    "                g = copy.deepcopy(job[i])\n",
    "                Scheduler.ICPCP.schedule(g, resources, makespan * deadline_factor)\n",
    "                if makespan * deadline_factor >= resources.makespan:\n",
    "                    break\n",
    "                else:\n",
    "                    deadline_factor = np.random.normal(8, 1.4) if random.random() >= 0.2 else np.random.normal(2, 1.4)\n",
    "            constraint_factor = deadline_factor\n",
    "            constraint_value = makespan * deadline_factor\n",
    "        if verbose:\n",
    "            print(\"heft cost:{0:5.1f} | cost:{1:5.1f} | heft ms:{2:5.2f} | ms:{3:5.2f} \"\n",
    "                  \"| Nodes:{4:4d} | {5:>8} | factor: {6:5.2f}\".format(cost, resources.plan_cost, makespan,\n",
    "                                                                      resources.makespan, len(g.tasks) - 2, c,\n",
    "                                                                      constraint_factor))\n",
    "\n",
    "        # ---Store results for next use:\n",
    "        makespan_list.append(resources.makespan)\n",
    "        cost_list.append(resources.plan_cost)\n",
    "        resources_set.append(copy.deepcopy(resources))\n",
    "        graph_set.append(g)\n",
    "        constraint_values.append(constraint_value)\n",
    "    return makespan_list, cost_list, resources_set, graph_set, constraint_values\n",
    "\n",
    "\n",
    "def show_schedule(resources, save_number=None, current_time=None):\n",
    "    sched = resources.show_schedule()\n",
    "\n",
    "    num_plots = sum([len(item[0]) for item in sched])\n",
    "    figure_number = random.randint(1, 10000)\n",
    "    fig = plt.figure(figure_number, figsize=[10,10])\n",
    "    colormap = plt.cm.gist_ncar\n",
    "    plt.gca().set_prop_cycle('color', [colormap(i) for i in np.linspace(0, 0.9, num_plots)])\n",
    "    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "    my_label = []\n",
    "    k = 0\n",
    "\n",
    "    for i, entry in enumerate(sched):\n",
    "        name = entry[0]\n",
    "        est = entry[1]\n",
    "        eft = entry[2]\n",
    "        for j in range(len(est)):\n",
    "#             print(f'({k}, {i}, {est[j]}, {eft[j]}),') ####################\n",
    "            k += 1\n",
    "            graph_name = name[j].split('-')[0]\n",
    "            first_visit = False\n",
    "            if not graph_name in my_label:\n",
    "                my_label.append(graph_name)\n",
    "                first_visit = True\n",
    "\n",
    "            my_color = my_label.index(graph_name)\n",
    "            if first_visit:\n",
    "                plt.plot([est[j], eft[j]], [i/5, i/5], linewidth=2, label=graph_name, \n",
    "                         color=colors[my_color])\n",
    "            else:\n",
    "                plt.plot([est[j], eft[j]], [i/5, i/5], linewidth=2, \n",
    "                         color=colors[my_color])\n",
    "\n",
    "    if current_time:\n",
    "        plt.plot([current_time, current_time], [0, len(sched)/5], linewidth=1, color='red')\n",
    "    plt.legend(loc='center')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(f'total cost: {resources.plan_cost}')\n",
    "    if not save_number is None:\n",
    "        plt.savefig(f'images/{save_number}', bbox_inches='tight')\n",
    "        plt.close(figure_number)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def create_multi_workflow_resouces(test, resources_set, constraint, cost_list, \n",
    "                                   makespan_list, job, graph_set, constraint_values):\n",
    "    timeslot = test.time_slot\n",
    "    bandwidth = test.bandwidth\n",
    "    #    workload_len = test.workload_len\n",
    "    powers = []\n",
    "    prices = []\n",
    "    numbers = []\n",
    "    for r in test.resource_array:\n",
    "        powers.append(r[0])\n",
    "        prices.append(r[1])\n",
    "        numbers.append(r[2])\n",
    "\n",
    "    workload_len = test.workload_len\n",
    "\n",
    "    # ----------------------- End of loading needed things.\n",
    "\n",
    "    # Preparing the resources in the cloud:\n",
    "\n",
    "    def type_of_resource(r_id):\n",
    "        limit = 0\n",
    "        for p in range(len(numbers)):\n",
    "            limit += numbers[p]\n",
    "            if r_id < limit:\n",
    "                return p\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    n = [0] * len(numbers)\n",
    "    for i in range(workload_len):\n",
    "        resources = resources_set[i]\n",
    "        for r in range(0, resources.len):\n",
    "            if resources.resource_cost(r) != 0:\n",
    "                n[type_of_resource(r)] += 1\n",
    "\n",
    "    c_resource = test.c_resource # the best was 0.8 in the tests # 0.4..1.2\n",
    "    for i in range(len(n)):\n",
    "        n[i] = int(n[i] * c_resource)\n",
    "\n",
    "    power_list, price_list, timeslot_list = [], [], []\n",
    "    for i in range(len(test.resource_array)):\n",
    "        power_list += [powers[i]] * n[i]\n",
    "        price_list += [prices[i]] * n[i]\n",
    "        # TODO: Tests must be changed, but it works for now (in case of change: both planner and main):\n",
    "        timeslot_list += [60 * timeslot] * n[i]\n",
    "\n",
    "    resource_spec = (power_list, price_list, timeslot_list)\n",
    "\n",
    "    # resource_spec = ([power1] * n[0] + [power2] * n[1] + [power3] * n[2],\n",
    "    #                  [price1] * n[0] + [price2] * n[1] + [price3] * n[2],\n",
    "    #                  [timeslot] * (n[0] + n[1] + n[2]))\n",
    "\n",
    "    cloud_resources = Definitions.Resources.CostAwareResources(resource_spec[0], resource_spec[1], resource_spec[2],\n",
    "                                                               bandwidth)\n",
    "\n",
    "    # -------- Making a multi-workflow list, which contains all workflows (they will schedule together)\n",
    "    jobs = []\n",
    "    for i in range(workload_len):\n",
    "        if constraint[i] is Constraint.deadline:\n",
    "            graph_set[i].makespan = makespan_list[i]  # resources_set[i].makespan\n",
    "        else:\n",
    "            graph_set[i].cost = cost_list[i]  # resources_set[i].plan_cost\n",
    "            graph_set[i].makespan = makespan_list[i]  # resources_set[i].makespan\n",
    "\n",
    "        prev_resources = resources_set[i]\n",
    "\n",
    "        job_item = JobItem(copy.deepcopy(job[i]), constraint[i],\n",
    "                           constraint_values[i], cloud_resources, graph_set[i], prev_resources)\n",
    "        jobs.append(job_item)\n",
    "\n",
    "    # prev_cloud_cost = 0\n",
    "    # previously_scheduled_graph = -1\n",
    "\n",
    "    current_critical = [0] * workload_len\n",
    "\n",
    "    # gap-rate calculation:\n",
    "    gap_rate = [0] * workload_len\n",
    "    s = gap_rate[:]\n",
    "    sum_task_number = sum(map(lambda graph: len(graph.tasks), graph_set))\n",
    "    for i in range(workload_len):\n",
    "        gap_rate[i] = resources_set[i].gap_rate\n",
    "        s[i] = len(graph_set[i].tasks) / (gap_rate[i] * sum_task_number)\n",
    "    iterator = min(s)\n",
    "    ref_s = s[:]\n",
    "    return jobs, cloud_resources\n",
    "\n",
    "def fair_policy(workload_len, jobs, cloud_resources,\n",
    "                show_online_schedule=False, arrivals=False):\n",
    "    # scheduling dummy tasks (get rid of them!):\n",
    "    for i in range(workload_len):\n",
    "        jobs[i].scheduler.schedule_next(do_head_nodes=True)\n",
    "        cloud_resources.costs = cloud_resources.price_of_each_graph()\n",
    "        # current_critical[i] = jobs[i].critical_now\n",
    "\n",
    "    figure_number = 1\n",
    "\n",
    "    # MAIN WHILE of Scheduler:\n",
    "    current_time = 0\n",
    "    while any([not job.scheduler.finished for job in jobs]):\n",
    "        cloud_resources.costs = cloud_resources.price_of_each_graph()\n",
    "        for i in range(len(jobs)):\n",
    "            job = jobs[i]\n",
    "            consumed_cost = cloud_resources.costs[job.g.name]\n",
    "            job.scheduler.remaining_budget = job.scheduler.total_budget - consumed_cost\n",
    "            job.scheduler.recalculate_sub_budget()\n",
    "\n",
    "        while all([job.scheduler.next_ready_task(current_time)==-1 for job in jobs]):\n",
    "            current_time = min([x for x in [job.scheduler.next_event(current_time) for job in jobs] if not x is None])\n",
    "        ready_list = [i for i, job in enumerate(jobs) if job.scheduler.next_ready_task(current_time) != -1]\n",
    "\n",
    "        most_critical = max([(jobs[ii].critical_now, ii) for ii in ready_list])[1]\n",
    "\n",
    "        if show_online_schedule:\n",
    "            show_schedule(cloud_resources, figure_number, current_time)\n",
    "        figure_number += 1\n",
    "\n",
    "        job = jobs[most_critical]\n",
    "\n",
    "        job.scheduler.schedule_next(do_head_nodes=True, arrival_time=current_time)\n",
    "\n",
    "\n",
    "def fair_policy_old(show_online_schedule=False, arrivals=False):\n",
    "    try:\n",
    "        # scheduling dummy tasks (get rid of them!):\n",
    "        for i in range(workload_len):\n",
    "            jobs[i].scheduler.schedule_next(do_head_nodes=True)\n",
    "            cloud_resources.costs = cloud_resources.price_of_each_graph()\n",
    "            # current_critical[i] = jobs[i].critical_now\n",
    "\n",
    "        figure_number = 1\n",
    "        ready_list = list(range(workload_len))\n",
    "\n",
    "        # MAIN WHILE of Scheduler:\n",
    "        arrival_time = 0\n",
    "        while ready_list:\n",
    "#             arrival_time += 10 # -------------------------------------------\n",
    "            cloud_resources.costs = cloud_resources.price_of_each_graph()\n",
    "            for i in range(len(jobs)):\n",
    "                job = jobs[i]\n",
    "                consumed_cost = cloud_resources.costs[job.g.name]\n",
    "                job.scheduler.remaining_budget = job.scheduler.total_budget - consumed_cost\n",
    "                job.scheduler.recalculate_sub_budget()\n",
    "\n",
    "            most_critical = -1\n",
    "            criticality = 100\n",
    "            ready_list_index = -1\n",
    "            for index, ii in enumerate(ready_list):\n",
    "                job = jobs[ii]\n",
    "                current_critical = job.critical_now\n",
    "                if current_critical < criticality:\n",
    "                    criticality = current_critical\n",
    "                    most_critical = ii\n",
    "                    ready_list_index = index\n",
    "\n",
    "            if show_online_schedule:\n",
    "                show_schedule(cloud_resources, figure_number)\n",
    "            figure_number += 1\n",
    "            job_index = most_critical  # ready_list[most_critical]\n",
    "            job = jobs[job_index]\n",
    "\n",
    "            del ready_list[ready_list_index]\n",
    "\n",
    "            job.scheduler.schedule_next(do_head_nodes=True, arrival_time=arrival_time)\n",
    "\n",
    "            if job.scheduler.finished:\n",
    "                continue\n",
    "            else:\n",
    "                ready_list.append(job_index)\n",
    "        return\n",
    "    except Exception as e:\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        print(exc_type, fname, exc_tb.tb_lineno)\n",
    "        raise e\n",
    "\n",
    "def show_results(cloud_resources, cost_list, makespan_list, constraint,\n",
    "                 constraint_values, jobs, graph_set, names, workload_len, resources_set):\n",
    "    # ------------ printing the result of scheduling:\n",
    "    print('calculating resource costs:')\n",
    "    costs = cloud_resources.price_of_each_graph()\n",
    "    print('done')\n",
    "    sum_separate = 0\n",
    "    s_e = []\n",
    "    print('+---+----------+--------+--------+--------+---------+--------+--------+------+------+')\n",
    "    print('|job|constraint| value  | ms old | ms new |prev cost|new cost|gap-rate|c-rate|m-rate|')\n",
    "    print('+---+----------+--------+--------+--------+---------+--------+--------+------+------+')\n",
    "    for i in range(len(jobs)):\n",
    "        prev_makespan = makespan_list[i]  # resources_set[i].makespan\n",
    "        if graph_set[i].endID not in cloud_resources.job_task_schedule[graph_set[i].name]:\n",
    "            print(\"|{:3d}|problem!\".format(i))\n",
    "            continue\n",
    "        cloud_makespan = cloud_resources.job_task_schedule[graph_set[i].name][graph_set[i].endID].EFT\n",
    "        prev_cost = cost_list[i]  # resources_set[i].plan_cost\n",
    "        cloud_cost = costs[graph_set[i].name]\n",
    "        m_rate = prev_makespan / cloud_makespan\n",
    "        c_rate = prev_cost / cloud_cost\n",
    "        if constraint[i] is Constraint.deadline:\n",
    "            c = ' Deadline '\n",
    "            m_rate = constraint_values[i] / cloud_makespan\n",
    "            s_e.append(c_rate)\n",
    "        else:\n",
    "            c = '  Budget  '\n",
    "            c_rate = constraint_values[i] / cloud_cost\n",
    "            s_e.append(m_rate)\n",
    "        print('|{:3d}|{}|{:8.3f}|{:8.3f}|{:8.3f}'\n",
    "              '|{:9.0f}|{:8.2f}|{:8.5f}|{:6.4f}|{:6.4f}|'\n",
    "              ''.format(i, c, constraint_values[i], prev_makespan, cloud_makespan,\n",
    "                        prev_cost, cloud_cost, resources_set[i].gap_rate,\n",
    "                        c_rate, m_rate))\n",
    "        deadline = -1\n",
    "        budget = -1\n",
    "        if constraint[i] is Constraint.deadline:\n",
    "            deadline = constraint_values[i]\n",
    "        else:\n",
    "            budget = constraint_values[i]\n",
    "\n",
    "        job_name = names[i]\n",
    "        job_size = len(graph_set[i].tasks) - 2\n",
    "\n",
    "        sum_separate += cost_list[i]  # resources_set[i].plan_cost\n",
    "    print('+---+----------+--------+--------+--------+---------+--------+--------+------+------+')\n",
    "\n",
    "    A = sum(s_e) / workload_len\n",
    "    sigma_u = 0\n",
    "    for se in s_e:\n",
    "        sigma_u += abs(se - A)\n",
    "    U = sigma_u / workload_len\n",
    "    print()\n",
    "    print(\"Overall Cloud Cost:{:6.3f}\".format(cloud_resources.plan_cost))\n",
    "    print(\"Separate Runs Cost:{:6.3f}\".format(sum_separate))\n",
    "    print(\"\\nUnfairness:{:8.5f}\".format(U))\n",
    "\n",
    "    cloud_resources_gap_rate = cloud_resources.gap_rate\n",
    "    print(\"\\nCloud gap-ratio:{:8.5f}\".format(cloud_resources_gap_rate))\n",
    "\n",
    "def is_successful(cloud_resources, cost_list, makespan_list, constraint,\n",
    "                  constraint_values, jobs, graph_set, names, workload_len):\n",
    "    costs = cloud_resources.price_of_each_graph()\n",
    "    sum_separate = 0\n",
    "    s_e = []\n",
    "    for i in range(len(jobs)):\n",
    "        prev_makespan = makespan_list[i]  # resources_set[i].makespan\n",
    "        if graph_set[i].endID not in cloud_resources.job_task_schedule[graph_set[i].name]:\n",
    "            print(\"|{:3d}|problem!\".format(i))\n",
    "            continue\n",
    "        cloud_makespan = cloud_resources.job_task_schedule[graph_set[i].name][graph_set[i].endID].EFT\n",
    "        prev_cost = cost_list[i]\n",
    "        cloud_cost = costs[graph_set[i].name]\n",
    "        m_rate = prev_makespan / cloud_makespan\n",
    "        c_rate = prev_cost / cloud_cost\n",
    "        if constraint[i] is Constraint.deadline:\n",
    "            c = ' Deadline '\n",
    "            m_rate = constraint_values[i] / cloud_makespan\n",
    "            if m_rate < 1:\n",
    "                print(f'it is {c} constrained, m_rate is {m_rate} -- constraint_values: {constraint_values[i]}, cloud_makespan: {cloud_makespan}')\n",
    "                return False\n",
    "            s_e.append(c_rate)\n",
    "        else:\n",
    "            c = '  Budget  '\n",
    "            c_rate = constraint_values[i] / cloud_cost\n",
    "            if c_rate < 1:\n",
    "                print(f'it is {c} constrained, c_rate is {c_rate} -- constraint_values: {constraint_values[i]}, cloud_cost: {cloud_cost}')\n",
    "                return False\n",
    "            s_e.append(m_rate)\n",
    "        deadline = -1\n",
    "        budget = -1\n",
    "        if constraint[i] is Constraint.deadline:\n",
    "            deadline = constraint_values[i]\n",
    "        else:\n",
    "            budget = constraint_values[i]\n",
    "\n",
    "        job_name = names[i]\n",
    "        job_size = len(graph_set[i].tasks) - 2\n",
    "\n",
    "        sum_separate += cost_list[i]  # resources_set[i].plan_cost\n",
    "\n",
    "    A = sum(s_e) / workload_len\n",
    "    sigma_u = 0\n",
    "    for se in s_e:\n",
    "        sigma_u += abs(se - A)\n",
    "    U = sigma_u / workload_len\n",
    "#     print(\"Overall Cloud Cost:{:6.3f}\".format(cloud_resources.plan_cost))\n",
    "#     print(\"Separate Runs Cost:{:6.3f}\".format(sum_separate))\n",
    "#     print(\"\\nUnfairness:{:8.5f}\".format(U))\n",
    "    if cloud_resources.plan_cost > sum_separate:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show\n",
    "[home](#home)\n",
    "\n",
    "[show all](#show-all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barbosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import Scheduler.Multi_Workflow\n",
    "from db.definitions import Test\n",
    "import pickle\n",
    "\n",
    "read_object = pickle.load(open('refrence_plan.pickle', 'rb'))\n",
    "bandwidth, workload_len, timeslot_list, powers, prices, numbers, power_list, price_list, timeslot_list, resource_spec, main_resources, makespan_list, cost_list, resources_set, graph_set, constraint_values = read_object\n",
    "\n",
    "\n",
    "jobs, cloud_resources = create_multi_workflow_resouces()\n",
    "barbosa()\n",
    "show_results()\n",
    "show_schedule(cloud_resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def barbosa():\n",
    "    try:\n",
    "        k = 1\n",
    "        # scheduling dummy tasks (get rid of them!):\n",
    "        for i in range(workload_len):\n",
    "            jobs[i].scheduler.schedule_next(do_head_nodes=True)\n",
    "            cloud_resources.costs = cloud_resources.price_of_each_graph()\n",
    "            # current_critical[i] = jobs[i].critical_now\n",
    "\n",
    "        ready_list = list(range(workload_len))\n",
    "        # MAIN WHILE of Scheduler:\n",
    "        while ready_list:\n",
    "            cloud_resources.costs = cloud_resources.price_of_each_graph()\n",
    "            for i in range(len(jobs)):\n",
    "                job = jobs[i]\n",
    "                consumed_cost = cloud_resources.costs[job.g.name]\n",
    "                job.scheduler.remaining_budget = job.scheduler.total_budget - consumed_cost\n",
    "                job.scheduler.recalculate_sub_budget()\n",
    "\n",
    "            k += 1\n",
    "            \n",
    "            most_critical = -1\n",
    "            criticality = 100\n",
    "            ready_list_index = -1\n",
    "            for index, ii in enumerate(ready_list):\n",
    "                job = jobs[ii]\n",
    "\n",
    "                SDi = job.scheduler.g.tasks[job.scheduler.last_unscheduled_task_id].sub_deadline\n",
    "                if hasattr(job.reference_graph, 'deadline'):\n",
    "                    Dj = job.reference_graph.deadline\n",
    "                else:\n",
    "                    Dj = job.reference_graph.makespan\n",
    "                TimeR = (Dj - SDi) / Dj\n",
    "\n",
    "                number_of_tasks = len(job.scheduler.priority_list)\n",
    "                PRTj = (number_of_tasks - job.scheduler.last_unscheduled_task_id) / number_of_tasks\n",
    "                \n",
    "#                 if k >= 200:\n",
    "#                     set_trace()\n",
    "\n",
    "                current_critical = TimeR * PRTj\n",
    "                if most_critical == -1 or current_critical < criticality:\n",
    "                    criticality = current_critical\n",
    "                    most_critical = ii\n",
    "                    ready_list_index = index\n",
    "\n",
    "            job_index = most_critical  # ready_list[most_critical]\n",
    "            job = jobs[job_index]\n",
    "            del ready_list[ready_list_index]\n",
    "\n",
    "            job.scheduler.schedule_next(do_head_nodes=True)\n",
    "\n",
    "            if job.scheduler.finished:\n",
    "                continue\n",
    "            else:\n",
    "                ready_list.append(job_index)\n",
    "        return\n",
    "    except Exception as e:\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        print(exc_type, fname, exc_tb.tb_lineno)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fair_policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create scheduling movie!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r images\n",
    "!mkdir images\n",
    "!ls images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "folder = 'images'\n",
    "filenames = [f'{folder}/{filename}.png' for filename in range(1, 1 + len(os.listdir(folder)))]\n",
    "images = []\n",
    "for filename in filenames:\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('movie4.gif', images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(cloud_resources.power, cloud_resources.price))\n",
    "cloud_resources.costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_resources.plan_cost/sum([costs[k] for k in costs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show all\n",
    "[home](#home)\n",
    "\n",
    "[show](#show)\n",
    "\n",
    "[barbosa method](#Barbosa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
